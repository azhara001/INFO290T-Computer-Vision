{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b55e27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import os \n",
    "import matplotlib.image as mpimg\n",
    "import time\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493b2714",
   "metadata": {},
   "source": [
    "## Importing image files using matplotlib.image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57eb6103",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"a2-images\"\n",
    "images_files = os.listdir(img_path)\n",
    "images=[]\n",
    "aligned_images = []\n",
    "\n",
    "for image in images_files:\n",
    "    unique_path = os.path.join('a2-images',image)\n",
    "    images.append(mpimg.imread(unique_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b4be3e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4732b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def offset_calculation(img1,img2):\n",
    "    # Use only the green channel for both the images\n",
    "    # You want to align each image to the FIRST IMAGE\n",
    "    pixel_range = 15\n",
    "    SSD = {}\n",
    "    img1_clipped,img2_clipped = img1[0:15,0:15,1],img2[0:15,0:15,1] #taking only the first 15x15 coordinates of Green Channel\n",
    "    \n",
    "    for i in range(pixel_range):\n",
    "        for j in range(pixel_range):\n",
    "            if i+j <= pixel_range:\n",
    "                img2_clipped_rolled = np.roll(img2_clipped,shift=(j),axis=1)\n",
    "                img2_clipped_rolled = np.roll(img2_clipped_rolled,shift=(i),axis=0)\n",
    "                SSD[f\"{i},{j}\"] = np.sum((img1_clipped-img2_clipped)**2)\n",
    "            else:\n",
    "                continue\n",
    "    return SSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d6a89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculating_min_SSD(SSD={}):\n",
    "    min_value = min(SSD.values())\n",
    "    \n",
    "    for key,value in SSD.items():\n",
    "        if value == min_value:\n",
    "            key_converted = key.split(\",\")\n",
    "            output = (key_converted[0],key_converted[1])\n",
    "        else:\n",
    "            continue\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274322c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaging_images(images=[]):\n",
    "    sum_ = np.zeros(1)\n",
    "    for i,image in enumerate(images):\n",
    "        print(image.shape)\n",
    "        sum_ = sum_+image\n",
    "    \n",
    "    average = sum_/i\n",
    "    print(i)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3903c",
   "metadata": {},
   "source": [
    "### int main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c59dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_list = []\n",
    "updated_list.append(images[0])\n",
    "\n",
    "for i,image in enumerate(images):\n",
    "    SSD = offset_calculation(images[0],image)\n",
    "    min_pair = calculating_min_SSD(SSD)\n",
    "    shifted = np.roll(image,shift=int(min_pair[0]),axis=0)\n",
    "    shifted = np.roll(shifted,shift=int(min_pair[1]),axis=1)\n",
    "    updated_list.append(np.roll(image,shift=(int(min_pair[0]),int(min_pair[1]))))\n",
    "    print(f\"image: {i} translated to: {int(min_pair[0])},{int(min_pair[1])} with min SSD: {min(SSD.values())}\")\n",
    "    plt.imshow(np.roll(image,shift=(int(min_pair[0]),int(min_pair[1]))))\n",
    "\n",
    "averaged_value = averaging_images(updated_list)\n",
    "plt.imshow(averaged_value)\n",
    "plt.savefig(\"Rectified Image.png\",dpi=500)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dba616c",
   "metadata": {},
   "outputs": [],
   "source": [
    "averaged_value.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c093e97f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ce8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1,2,3,4,5])\n",
    "b = np.array([10,20,30,40,50])\n",
    "c = np.array([100,200,300,400,500])\n",
    "lee = [a,b,c]\n",
    "\n",
    "avg = (a+b+c)/3\n",
    "print(avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30945a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef26fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "testing = np.zeros((5,5))\n",
    "testing[0,0] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfee84e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2_clipped_rolled = np.roll(testing,shift=(1),axis=1)\n",
    "img2_clipped_rolled = np.roll(img2_clipped_rolled,shift=(0),axis=0)\n",
    "plt.imshow(img2_clipped_rolled)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c408f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2_clipped_rolled = np.roll(testing,shift=(2),axis=1)\n",
    "img2_clipped_rolled = np.roll(img2_clipped_rolled,shift=(0),axis=0)\n",
    "plt.imshow(img2_clipped_rolled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12e5c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2_clipped_rolled = np.roll(testing,shift=(3),axis=1)\n",
    "img2_clipped_rolled = np.roll(img2_clipped_rolled,shift=(0),axis=0)\n",
    "plt.imshow(img2_clipped_rolled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bb7057",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2_clipped_rolled = np.roll(testing,shift=(4),axis=1)\n",
    "img2_clipped_rolled = np.roll(img2_clipped_rolled,shift=(0),axis=0)\n",
    "plt.imshow(img2_clipped_rolled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1862ab2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2_clipped_rolled = np.roll(testing,shift=(0),axis=1)\n",
    "img2_clipped_rolled = np.roll(img2_clipped_rolled,shift=(1),axis=0)\n",
    "plt.imshow(img2_clipped_rolled)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7911c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2_clipped_rolled = np.roll(testing,shift=(0),axis=1)\n",
    "img2_clipped_rolled = np.roll(img2_clipped_rolled,shift=(3),axis=0)\n",
    "plt.imshow(img2_clipped_rolled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592105af",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2_clipped_rolled = np.roll(testing,shift=(4),axis=1)\n",
    "img2_clipped_rolled = np.roll(img2_clipped_rolled,shift=(4),axis=0)\n",
    "plt.imshow(img2_clipped_rolled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43341c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
